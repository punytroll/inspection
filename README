Patterns:
================================
These patterns need to spread to all getter implementations:
1. "Continue" pattern: A local variable named "Continue" tracks, whether the getter should continue its work. If this variable becomes false, the getter should fall through to returning the Result. Every reading of subsequent parts (as well as verification and interpretation) should be surrounded by a "if(Continue == true)" query.
2. "Field" pattern: Instead of long variable names that refer to parts of the original format specification (like "OwnerIdentifierResult"), the general name "FieldResult" should be used.
3. "Part" pattern: Instead of FieldReader, FieldResult and FieldValue, PartReader, PartResult and PartValue should be used.
4. "SubReader" pattern: Every part should be read from its own reader, because that assures, that every getter starts at the postiion 0.
5. "NoValue" pattern: Don't create the local variable FieldValue or PartValue.
6. "ValueAfterContinue": First update the Continue variable, then append the PartValue to the result.
7. "NoUpdateState": All calls to different versions of UpdateState should be replaced by the specific lines "Continue = PartResult->GetSuccess()" and "Reader.AdvancePosition(FieldReader.GetConsumedLength())". These two lines may need to be placed separatly instead of adjoint.
8. "AdvanceAfterValue": Append the value and THEN advance the reader position.
9. "NoLoops": Getters must not implement their own loops but defer to multi-purpose array getters.
10. "NoLengthVerification": Getters which defer to other getters instead of accessing the Reader directly, should do no verification step on the available length.
11. "ExplicitArrays": Whenever using arrays, always append the array value instead of appending the items of the array.
12. "NoLengthExceptFromData": Don't try to restrict a sub readers range based on programmer knowledge, how long it will be. (Like 4 byte for an unsigned 32bit integer.) Only use length restrictions from data.
13. "InterpretationAlwaysContinues": Just because an interpretation (like looking up an enum) fails, doesn't mean, that reading should discontinue. This program is intended extract as much data as possible from the whole file, so it should just abruptly stop if it finds a value that doesn't belong there. Instead, an error message should be appended, and maybe also a "null"-interpretation.
14. "Parameters": All hardcoded getters should be implemented with a Parameters parameter, an unordered map from string to any.
15. "Elements": In all array reading getters, the parts that constitute the array are called Elements.
16. "ElementGetter": The getter referenced in the parameters for array getters is called "ElementGetter".
17. "ElementIndexInArray": All array functions must pass a parameter "ElementIndexInArray" to the element getter.
18. "HardcodedCalls": Whenever a hardcoded getter calls another hardcoded getter, for performance reasons, it should do so directly, not via the getter repository.

On the history of getters:
================================

1st generation getters:
-----------------------
These functions perfom no validating on the input - they simply expect the input to be valid. On faulty input assertions, exceptions or segmentation faults may occur. Also wrong output may be produced for faulty input.

Obviously the major drawback was the missing input validation. This was fixed with side-by-side version of validator functions, which had to be called prior to calling the getters to assert, that reading the value was safe to do. But in most cases this meant iterating over the input twice, resulting in doubled reading time. The second generation of getters was required to validate and extract in one go and report the result of their validation step back to the caller.


2nd generation getters:
-----------------------
These functions validate and extract a value in one go. They have two or three return values contained in a return tuple. The first tuple component is a boolean value indicating the success of getting the desired value from the data block. If a value could be extracted successfully, the second value conatins an integer value indicating the length of the processed data. The third value, which may be omitted, is templated with different types and contains the actual result value. If the success return value is false, the length and return values may contain bogus data.

The major drawback is the single return value. In particular this setup made it necessary to separate reading a value from interpreting it. Therefore the third generation was required to allow multiple return values.


3rd generation getters:
-----------------------
These functions validate and extract in one go. They have three return values contained in a return tuple. The first tuple component is a boolean value indicating success (type bool). If a value could be extracted successfully, the second value is an integer, indicating the length of the processed data. The third value is an object of the type Values (see below). If the boolean success return value is false, the length and return values may contain bogus data.

The major drawback is the return-by-value semantic. The Values object is returned by value which means a lot of copying around. Also, when getters begin to aggregate values from different fields into one return value and and even cascade Values objects, the copying got out of hand. The fourth generation of getters was required to pass objects by reference.

Class "Values":
---------------
Is an associative container, mapping from string to an any value. The any value is contained by value.


4th generation getters:
-----------------------
These functions validate and extract in one go. They return a unique_ptr to an instance of type Result (see below).

Class "Result":
---------------
Came about as a helper class to incorporate sucess, length and result into one value. Also, this class was designed to be returned inside a unique_ptr, making it clear that the result of a getter can only be processed are passed around once, not to be contained in the result of another getter. The result value is carried by shared_ptr, which highlights the fact, that this value can be extracted and used in other places.


5th generation getters:
-----------------------
This generation finally allows bit-precise access to data. A new class Length is responsible for storing byte-and-bit-pairs and a new class Buffer uses that functionality to allow reading from 0 to 8 bits in one uint8_t value. Multiple such values have to be combined in the getters to synthesize larger values. The buffer advances its internal position according to the data that has already been read, thus removing the necessity to advance the index by hand.


6th generation getters:
-----------------------
The 6th generation of getters resulted from the Reader branch, which implemented a Reader class. This class implements a view of a buffer, defined by a starting offset inside the buffer, a current position inside the buffer, and a boundary position inside the buffer. Reading outside of the reader's accessible portion of the buffer is not allowed, thereby restricting the reach of reading. Getters, which worked directly on the Buffer class, were transformed using the Reader class, which was a long an incremental process. To distinguish getters that had been transformed to using the Reader class, those were called readers as well, but this name is not valid anymore.
The readers made specifying an allowed length unnecessary for getters, because the length restriction could be encoded in the reader instance.

7th generation getters:
-----------------------
The 7th generation of getters is just a minor extension. By adding an unordered dictionary of key-value-pairs, the work of a getter can be parameterized by the caller. This is mostly used for dynamic information that is not generally known when writing the caller. For performance reasons it is not desireable to convert every distinct behavior into a parameter for an even more complex getter. Not all getters have been converted yet.

8th generation getters (readers):
---------------------------------
This was not really a new generation of getters but a new generation of the basis that made getters work. Readers in the 6th generation were always working directly on the one and only buffer that contained the whole file. Positions in the reader class were given in absolute positions inside the buffer. Child readers created from parent readers, inherited the buffer of the parent und took on absolute positions inside the buffer, based on the positions of the parent reader.
There were problems with that approach however. In particular the unsynchronization scheme of ID3 tags was quite difficult to handle, because in addition to the required knowledge of the data format, it requires simultaneous knowledge and handling of the de-unsynchronization scheme. These two aspects of reading and interpreting data are perfectly orthogonal and should be taken care of separately.
The second problem that was never even attempted to be solved was that of segmentation of data in OggStream. A single Packet might span multiple segments, which is not that difficult to handle, because segments are directly adjacent without any in-between data. However, they might also span multiple Pages and in that case the data is not continuous, because of page headers in between. Again, knowledge of the data format would have to be applied at the same time as knowledge of the segmentation scheme. Again, these two aspects are perfectly orthogonal.
The answer to both problems is the abstract DataSource class and its implementations. The most basic of these implementations is the Buffer itself, a DataSource that just returns the data in the internal buffer. A second implementation is a de-unsynchronization filter, that returns data to the caller, but removes the superfluous bytes used to unsynchronize the data. The third implementation of the basic data source is a segmented buffer, which contains references to multiple sequences of data in other data sources and concatenates them transparently to give the impression of a single continuous sequence of data.
